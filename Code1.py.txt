# === Step 1: Import Required Libraries ===
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score, cross_val_predict, KFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay

# Classifiers
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

# Set style for plots
sns.set(style="whitegrid")



# === Step 2: Load the Dataset ===
iris = load_iris()
X = iris.data
y = iris.target
feature_names = iris.feature_names
class_names = iris.target_names

print("Features:", feature_names)
print("Classes:", class_names)
print("Shape of X:", X.shape)
print("Shape of y:", y.shape)




# === Step 3: Create Classifier Models ===
models = {
    'Logistic Regression': LogisticRegression(max_iter=200),
    'Support Vector Machine': SVC(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'K-Nearest Neighbors': KNeighborsClassifier()
}



# === Step 4: Define 5-Fold Cross-Validation ===
kf = KFold(n_splits=5, shuffle=True, random_state=42)





# === Step 5: Train and Evaluate Each Model ===
results = []

for name, model in models.items():
    print(f"\n----- {name} -----")
    
    # Accuracy via 5-fold cross-validation
    scores = cross_val_score(model, X, y, cv=kf)
    mean_acc = np.mean(scores)
    print("Cross-Validation Scores:", scores)
    print(f"Mean Accuracy: {mean_acc:.2f}")
    
    # Predictions from cross-validation
    y_pred = cross_val_predict(model, X, y, cv=kf)
    
    # Confusion Matrix
    cm = confusion_matrix(y, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues)
    plt.title(f"Confusion Matrix - {name}")
    plt.show()
    
    # Classification Report
    print("Classification Report:")
    print(classification_report(y, y_pred, target_names=class_names))
    
    # Save results
    results.append({
        'Model': name,
        'Mean Accuracy': mean_acc
    })
    



# === Step 6: Compare Model Accuracies ===
results_df = pd.DataFrame(results)
plt.figure(figsize=(8, 5))
sns.barplot(data=results_df, x='Model', y='Mean Accuracy', palette='Set2')
plt.title("Model Comparison - Mean Accuracy (5-Fold CV)")
plt.ylabel("Accuracy")
plt.ylim(0.8, 1.0)
plt.xticks(rotation=45)
plt.show()